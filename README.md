# EmotionDetection

Problem Statement: For the given dataset, you have to develop a video analytics model to predict the underlying emotion of the person in the video. For the prediction, ONLY the visual component of the video is to be used, and NOT the audio. Expected predictions: The category of emotion: Anger/ disgust/ fear/ happy/ neutral/ sad Emotion level (not necessary, but encouraged)

The Actor id is a 4 digit number at the start of the file. Each subsequent identifier is separated by an underscore (_). 
Actors spoke from a selection of 12 sentences (in parentheses is the three letter acronym used in the second part of the filename): 
It's eleven o'clock (IEO).
That is exactly what happened (TIE). 
I'm on my way to the meeting (IOM).
I wonder what this is about (IWW). 
The airplane is almost full (TAI).
Maybe tomorrow it will be cold (MTI).
I would like a new alarm clock (IWL).
I think I have a doctor's appointment (ITH).
Don't forget a jacket (DFA).
I think I've seen this before (ITS). 
The surface is slick (TSI).
We'll stop in a couple of minutes (WSI).
The sentences were presented using different emotion (in parentheses is the three letter code used in the third part of the filename): Anger (ANG) Disgust (DIS) Fear (FEA) Happy/Joy (HAP) Neutral (NEU) Sad (SAD) and emotion level (in parentheses is the two letter code used in the fourth part of the filename): Low (LO) Medium (MD) High (HI) Unspecified (XX) Submission: The submission will be in the form a well-documented python notebook having the code.
Dataset Link: https://www.oulu.fi/en/university/faculties-and-units/faculty-information-technology-and-electrical-engineering/center-machine-vision-and-signal-analysis
